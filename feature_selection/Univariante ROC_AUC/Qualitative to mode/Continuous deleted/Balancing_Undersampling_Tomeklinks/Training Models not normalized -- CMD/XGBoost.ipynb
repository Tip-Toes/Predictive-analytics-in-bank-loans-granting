{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_algo_path():\n",
    "    import os\n",
    "    cwd = os.getcwd()\n",
    "    s='\\\\'\n",
    "    if '\\\\' not in cwd:\n",
    "        s='/'\n",
    "    cwd= cwd.split(s)[4:-1]\n",
    "    cwd.append('Not Normalized')\n",
    "    cwd='/'.join(cwd)\n",
    "    return cwd\n",
    "\n",
    "def get_csv_path():\n",
    "    import os\n",
    "    cwd = os.getcwd()\n",
    "    s=\"\\\\\"\n",
    "    if \"\\\\\" not in cwd:\n",
    "        s='/'\n",
    "    file= cwd.split(s)[:4]\n",
    "    file.append('models_scores.csv')\n",
    "    file= s.join(file)\n",
    "    return file\n",
    "\n",
    "def line_is_exist(file, row):\n",
    "    logfile = open(file, 'r')\n",
    "    loglist = logfile.readlines()\n",
    "    logfile.close()\n",
    "    for line in loglist:\n",
    "        if ','.join(row) in line:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def write_new_score(file, line):\n",
    "    if( not line_is_exist(file, line) ):\n",
    "        with open(file, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(line)\n",
    "    else:\n",
    "        print('line exsist already')\n",
    "  \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv('../data.csv')\n",
    "##copying data\n",
    "data1=data.copy()\n",
    "### spliting data en X et Y\n",
    "X= data1.drop('Loan Status', axis=1)\n",
    "Y= data1['Loan Status']\n",
    "### spliting the data to train and test\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 123)\n",
    "### XGBoost\n",
    "## converting Y_train & X_test & Y_train & Y_test to numpy array pour XGBoost\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_test = Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "xgb= XGBClassifier()\n",
    "params= {\n",
    "        'max_depth': [5, 6, 7, 8, 9, 10, 11, 12, 13,14],\n",
    "        'n_estimators' : [100, 300, 500, 800]\n",
    "        }\n",
    "\n",
    "##accuracy\n",
    "grid_search_acc= GridSearchCV(estimator=xgb, param_grid= params, scoring='accuracy',cv=2, n_jobs=-1)\n",
    "grid_search_acc= grid_search_acc.fit(X_train, Y_train)\n",
    "y_predict= grid_search_acc.best_estimator_.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "## get avg precision & avg recall\n",
    "report= classification_report(Y_test, y_predict, output_dict=True)\n",
    "avg_list = report.pop(\"weighted avg\")\n",
    "avg_precision= round(avg_list['precision'], 3)\n",
    "avg_recall= round(avg_list['recall'], 3)\n",
    "accuraccy= round(accuracy_score(Y_test,y_predict), 3)\n",
    "## csv row\n",
    "csv_row = [get_algo_path(), 'XGBoost', str(grid_search_acc.best_params_), str(accuraccy), str(avg_precision), str(avg_recall)]\n",
    "## write file\n",
    "csv_file= get_csv_path()\n",
    "write_new_score(csv_file, csv_row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "----------\n",
      "best parameters:  {'max_depth': 8, 'n_estimators': 100}\n",
      "----------\n",
      "[[11576  3783]\n",
      " [  132 15275]]\n",
      "----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.86     15359\n",
      "           1       0.80      0.99      0.89     15407\n",
      "\n",
      "    accuracy                           0.87     30766\n",
      "   macro avg       0.90      0.87      0.87     30766\n",
      "weighted avg       0.89      0.87      0.87     30766\n",
      "\n",
      "----------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## evaluating the model\n",
    "print(\"----------\")\n",
    "print('best parameters: ', grid_search_acc.best_params_)\n",
    "print(\"----------\")\n",
    "print(confusion_matrix(Y_test,y_predict))\n",
    "print(\"----------\")\n",
    "print(classification_report(Y_test, y_predict))\n",
    "print(\"----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}