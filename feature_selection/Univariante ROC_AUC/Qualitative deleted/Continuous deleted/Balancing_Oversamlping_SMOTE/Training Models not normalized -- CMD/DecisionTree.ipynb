{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Omar\\\\00_Bank_loan_project\\\\models_scores.csv'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "'feature_selection/Univariante ROC_AUC/Qualitative deleted/Continuous deleted/Balancing_Oversamlping_SMOTE/Not Normalized'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 41
    }
   ],
   "source": [
    "def get_algo_path():\n",
    "    import os\n",
    "    cwd = os.getcwd()\n",
    "    s='\\\\'\n",
    "    if '\\\\' not in cwd:\n",
    "        s='/'\n",
    "    cwd= cwd.split(s)[4:-1]\n",
    "    cwd.append('Not Normalized')\n",
    "    cwd='/'.join(cwd)\n",
    "    return cwd\n",
    "\n",
    "def get_csv_path():\n",
    "    import os\n",
    "    cwd = os.getcwd()\n",
    "    s=\"\\\\\"\n",
    "    if \"\\\\\" not in cwd:\n",
    "        s='/'\n",
    "    file= cwd.split(s)[:4]\n",
    "    file.append('models_scores.csv')\n",
    "    file= s.join(file)\n",
    "    return file\n",
    "\n",
    "def line_is_exist(file, row):\n",
    "    logfile = open(file, 'r')\n",
    "    loglist = logfile.readlines()\n",
    "    logfile.close()\n",
    "    for line in loglist:\n",
    "        if ','.join(row) in line:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def write_new_score(file, line):\n",
    "    if( not line_is_exist(file, line) ):\n",
    "        with open(file, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(line)\n",
    "    else:\n",
    "        print('line exsist already')\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file= get_csv_path()\n",
    "fields=['fidrst','secxodnsd','third']\n",
    "write_new_score(csv_file, fields)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv('../data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##copying data\n",
    "data1=data.copy()\n",
    "### spliting data en X et Y\n",
    "X= data1.drop('Loan Status', axis=1)\n",
    "Y= data1['Loan Status']\n",
    "### spliting the data to train and test\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 123)\n",
    "## dicision tree (CART)\n",
    "dct = DecisionTreeClassifier()\n",
    "params={'criterion' : ['gini', 'entropy'],\n",
    "        'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13,14, 15, 16, 17, None]}\n",
    "\n",
    "##accuracy\n",
    "grid_search_acc= GridSearchCV(estimator=dct, param_grid= params, scoring='accuracy',cv=10, n_jobs=-1)\n",
    "grid_search_acc= grid_search_acc.fit(X_train, Y_train)\n",
    "y_predict= grid_search_acc.best_estimator_.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "best parameters:  {'criterion': 'entropy', 'max_depth': 14}\n",
      "----------\n",
      "[[11872  3487]\n",
      " [ 1802 13605]]\n",
      "----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82     15359\n",
      "           1       0.80      0.88      0.84     15407\n",
      "\n",
      "    accuracy                           0.83     30766\n",
      "   macro avg       0.83      0.83      0.83     30766\n",
      "weighted avg       0.83      0.83      0.83     30766\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "## evaluating the model\n",
    "print(\"----------\")\n",
    "print('best parameters: ', grid_search_acc.best_params_)\n",
    "print(\"----------\")\n",
    "print(confusion_matrix(Y_test,y_predict))\n",
    "print(\"----------\")\n",
    "print(classification_report(Y_test, y_predict))\n",
    "print(\"----------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}