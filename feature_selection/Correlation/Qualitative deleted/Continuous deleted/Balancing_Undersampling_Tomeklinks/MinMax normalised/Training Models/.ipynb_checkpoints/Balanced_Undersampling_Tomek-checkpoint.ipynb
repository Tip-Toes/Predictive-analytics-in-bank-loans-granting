{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv('../z_norm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['Loan Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data en X et Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data1= data.copy()\n",
    "X= data1.drop('Loan Status', axis=1)\n",
    "Y= data1['Loan Status']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X= pd.get_dummies(X, drop_first= True)\n",
    "Y= pd.get_dummies(Y, drop_first= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tl =TomekLinks()\n",
    "X , Y = tl.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train , Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 123, stratify=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([12971, 37560], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---KNN---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "##Hyperparameter tuning     ##5*4*10= 200 training \n",
    "params={'n_neighbors' : [2, 3, 4, 5, 6, 7, 8],\n",
    "        'metric': ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "##accuracy\n",
    "grid_search_acc= GridSearchCV(estimator=knn, param_grid= params, scoring='accuracy',cv=5, n_jobs=-1)\n",
    "grid_search_acc= grid_search_acc.fit(X_train, Y_train)\n",
    "y_predict= grid_search_acc.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "best parameters:  {'metric': 'manhattan', 'n_neighbors': 7}\n",
      "----------\n",
      "[[1144 2099]\n",
      " [ 708 9547]]\n",
      "----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.35      0.45      3243\n",
      "           1       0.82      0.93      0.87     10255\n",
      "\n",
      "    accuracy                           0.79     13498\n",
      "   macro avg       0.72      0.64      0.66     13498\n",
      "weighted avg       0.77      0.79      0.77     13498\n",
      "\n",
      "----------\n",
      "best accuracy:  0.7961449407294532\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "## evaluating the model\n",
    "print(\"----------\")\n",
    "print('best parameters: ', grid_search_acc.best_params_)\n",
    "print(\"----------\")\n",
    "print(confusion_matrix(Y_test,y_predict))\n",
    "print(\"----------\")\n",
    "print(classification_report(Y_test, y_predict))\n",
    "print(\"----------\")\n",
    "print('best accuracy: ', grid_search_acc.best_score_)\n",
    "print(\"----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## precision\n",
    "grid_search_rec= GridSearchCV(estimator=knn, param_grid= params, scoring='recall',cv=5, n_jobs=-1)\n",
    "grid_search_rec= grid_search_rec.fit(X_train, Y_train)\n",
    "y_predict= grid_search_rec.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## evaluating the model\n",
    "print(\"----------\")\n",
    "print('best parameters: ', grid_search_rec.best_params_)\n",
    "print(\"----------\")\n",
    "print(confusion_matrix(Y_test,y_predict))\n",
    "print(\"----------\")\n",
    "print(classification_report(Y_test, y_predict))\n",
    "print(\"----------\")\n",
    "print('best recall: ', grid_search_rec.best_score_)\n",
    "print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  864  2379]\n",
      " [    1 10254]]\n",
      "----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.42      3243\n",
      "           1       0.81      1.00      0.90     10255\n",
      "\n",
      "    accuracy                           0.82     13498\n",
      "   macro avg       0.91      0.63      0.66     13498\n",
      "weighted avg       0.86      0.82      0.78     13498\n",
      "\n",
      "----------\n",
      "Score:  0.8236775818639799\n"
     ]
    }
   ],
   "source": [
    "## precision\n",
    "grid_search_prec= GridSearchCV(estimator=knn, param_grid= params, scoring='precision',cv=5, n_jobs=-1)\n",
    "grid_search_prec= grid_search_prec.fit(X_train, Y_train)\n",
    "y_predict= grid_search_prec.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## evaluating the model\n",
    "print(\"----------\")\n",
    "print('best parameters: ', grid_search_prec.best_params_)\n",
    "print(\"----------\")\n",
    "print(confusion_matrix(Y_test,y_predict))\n",
    "print(\"----------\")\n",
    "print(classification_report(Y_test, y_predict))\n",
    "print(\"----------\")\n",
    "print('best precision: ', grid_search_prec.best_score_)\n",
    "print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_grid_search(cv_results, grid_param_1, grid_param_2, name_param_1, name_param_2):\n",
    "    # Get Test Scores Mean and std for each grid search\n",
    "    scores_mean = cv_results['mean_test_score']\n",
    "    scores_mean = np.array(scores_mean).reshape(len(grid_param_2),len(grid_param_1))\n",
    "\n",
    "    # Plot Grid search scores\n",
    "    _, ax = plt.subplots(1,1)\n",
    "\n",
    "    # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "    for idx, val in enumerate(grid_param_2):\n",
    "        ax.plot(grid_param_1, scores_mean[idx,:], '-o', label= name_param_2 + ': ' + str(val))\n",
    "\n",
    "    ax.set_title(\"Oversampling_SMOTE\", fontsize=18, fontweight='bold')\n",
    "    ax.set_xlabel(name_param_1, fontsize=14)\n",
    "    ax.set_ylabel('Accuracy [CV Avg Score]', fontsize=14)\n",
    "    ax.legend(loc=\"best\", fontsize=15)\n",
    "    ax.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: \n",
      "---------------\n",
      "scores:  [0.795, 0.793, 0.796, 0.794, 0.786, 0.791, 0.784, 0.791, 0.791, 0.784]\n",
      "Mean score:  0.79\n",
      "standart deviation:  0.004\n",
      "\n",
      "SVC: \n",
      "---------------\n",
      "scores:  [0.817, 0.807, 0.817, 0.816, 0.806, 0.811, 0.803, 0.811, 0.814, 0.809]\n",
      "Mean score:  0.811\n",
      "standart deviation:  0.004\n"
     ]
    }
   ],
   "source": [
    "# Calling Method \n",
    "plot_grid_search(grid_search_acc.cv_results_, params['n_neighbors'], params['metric'], 'N neighbors', 'Metric')\n",
    "plot_grid_search(grid_search_rec.cv_results_, params['n_neighbors'], params['metric'], 'N neighbors', 'Metric')\n",
    "plot_grid_search(grid_search_prec.cv_results_, params['n_neighbors'], params['metric'], 'N neighbors', 'Metric')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
